{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 Yasin Ünal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu ödevin amacı perceptron yapısını anlamak ve ileri yayılım/geri yayılım ile bir ağı eğitmektir. Bu eğitilen ağ ile lineer bir sınıflandırıcı elde edilerek resim sınıfı (iki sınıflı) tahmini yapılacaktır. Bu resimlerden 29 farklı feature çıkarımı yapılıp bias ile (30, ) boyutunda veriler kullanılacaktır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Öncelikle aktivasyon fonksiyonlarının tanımlanması ile başlayalım. \n",
    "Swish aktivasyon fonksiyonu ve türevi aşağıdaki gibidir\n",
    "\n",
    "<img src=\"https\n",
    "://media.geeksforgeeks.org/wp-content/uploads/20200516225910/swish.jpeg\" width=\"350\" height=\"350\">\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidp(x):\n",
    "    x = np.clip(x, -500, 500)  # Overflow önleme\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def Swish(x):\n",
    "    x = np.clip(x, -100, 100)  \n",
    "    return x * sigmoidp(x)\n",
    "\n",
    "def dSwish(x):\n",
    "    x = np.clip(x, -100, 100)\n",
    "    sig = sigmoidp(x)\n",
    "    return sig + x * sig * (1 - sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "Sonraki adımda resim verilerinden (image_vector) feature extraction işlemini gerçekleştireceğiz. Bunun için ödevde tanımlanan 29 adet işlem tanımlanarak bir listeye eklenip return edilmiştir. Feature extraction işlemleri için Deepseek'den yardım alınmıştır.\n",
    "\n",
    "| **Feature**             | **Description**                                                                          | **Number of Features** |\n",
    "|-------------------------|------------------------------------------------------------------------------------------|------------------------|\n",
    "| **1. Mean**                | Average values of all pixels in a studied area                                          | 3                      |\n",
    "| **2. Entropy**             | Measure of energy behind all pixels                                                     | 3                      |\n",
    "| **3. Standard Deviation**  | Factor of variation for all pixels                                                      | 3                      |\n",
    "| **4. Skewness**            | Measure of third moment of all pixels and refers to symmetric behavior of data          | 3                      |\n",
    "| **5. Moment**              | Refers to second moment of all pixels                                                   | 3                      |\n",
    "| **6. Mean FFT**            | Average values of all pixels after the Fourier transform                                | 3                      |\n",
    "| **7. Percentile**          | Indicates the 50% percentile of all pixels                                              | 3                      |\n",
    "| **8. Median**              | Middle value of sorted pixels                                                           | 3                      |\n",
    "| **9. Brightness Index**    | \\((R^2 + G^2 + B^2) / 3\\)                                                                | 1                      |\n",
    "| **10. Saturation Index**    | \\(\\frac{(R - B)}{(R + B)}\\)                                                             | 1                      |\n",
    "| **11. Hue Index**           | \\(\\frac{(2 \\times R - G - B)}{(G - B)}\\)                                                | 1                      |\n",
    "| **12. Coloration Index**    | \\(\\frac{(R - G)}{(R + G)}\\)                                                             | 1                      |\n",
    "| **13. Redness Index**       | \\(\\frac{(R^2)}{\\bigl(B \\times (G^3)\\bigr)}\\)                                            | 1                      |\n",
    "| **Total number of features** |                                                                                    | **29**                 |\n",
    "\n",
    "\n",
    "Not : FFT imajiner sayılar oluşturabilir. Bu yüzden abs kullanıldı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(image_vector):\n",
    "    # Görüntüyü (128, 128, 3) şekline getir\n",
    "    img = image_vector.reshape(128, 128, 3)\n",
    "    \n",
    "    # Renk kanalları\n",
    "    red = img[:,:,0]\n",
    "    green = img[:,:,1]\n",
    "    blue = img[:,:,2]\n",
    "    \n",
    "    # Sıfıra bölme hatalarından kaçınmak için epsilon değeri\n",
    "    eps = 1e-10\n",
    "    \n",
    "    # HSV dönüşümü\n",
    "    img_hsv = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Özellik listesi\n",
    "    features = []\n",
    "    \n",
    "    # 1. Mean R, G, B (3 features)\n",
    "    for i in range(3):\n",
    "        features.append(np.mean(img[:,:,i]))\n",
    "        \n",
    "    # 2. Entropi R, G, B (3 features)\n",
    "    for i in range(3):\n",
    "        # Entropi hesaplaması için histogram kullan (daha doğru sonuç verir)\n",
    "        hist, _ = np.histogram(img[:,:,i], bins=256, range=(0, 256), density=True)\n",
    "        entropy = -np.sum(hist * np.log2(hist + eps))\n",
    "        features.append(entropy)\n",
    "    \n",
    "    # 3. Standart sapma R, G, B (3 features)\n",
    "    for i in range(3):\n",
    "        features.append(np.std(img[:,:,i]))\n",
    "    \n",
    "    # 4. Skewness R, G, B (3 features)\n",
    "    for i in range(3):\n",
    "        features.append(stats.skew(img[:,:,i].flatten()))\n",
    "    \n",
    "    # 5. Moment R, G, B (3 features) - İkinci moment (tabloda belirtildiği gibi)\n",
    "    for i in range(3):\n",
    "        features.append(stats.moment(img[:,:,i].flatten(), moment=2))\n",
    "    \n",
    "    # 6. Mean FFT R, G, B (3 features)\n",
    "    for i in range(3):\n",
    "        fft = np.fft.fft2(img[:,:,i])\n",
    "        features.append(np.mean(np.abs(fft)))\n",
    "    \n",
    "    # 7. Percentile R, G, B (3 features) - 50. percentile\n",
    "    for i in range(3):\n",
    "        features.append(np.percentile(img[:,:,i], 50))\n",
    "    \n",
    "    # 8. Median R, G, B (3 features)\n",
    "    for i in range(3):\n",
    "        features.append(np.median(img[:,:,i]))\n",
    "    \n",
    "    # 9. Brightness Index (1 feature) - (R^2 + G^2 + B^2) / 3\n",
    "    brightness = (np.mean(red**2) + np.mean(green**2) + np.mean(blue**2)) / 3.0\n",
    "    features.append(brightness)\n",
    "    \n",
    "    # 10. Saturation Index (1 feature) - (R - B) / (R + B)\n",
    "    sat_index = (np.mean(red) - np.mean(blue)) / (np.mean(red) + np.mean(blue) + eps)\n",
    "    features.append(sat_index)\n",
    "    \n",
    "    # 11. Hue Index (1 feature) - (2*R - G - B) / (G - B)\n",
    "    hue_index = ((2 * np.mean(red)) - np.mean(green) - np.mean(blue)) / (np.mean(green) - np.mean(blue) + eps)\n",
    "    features.append(hue_index)\n",
    "    \n",
    "    # 12. Coloration Index (1 feature) - (R - G) / (R + G)\n",
    "    color_index = (np.mean(red) - np.mean(green)) / (np.mean(red) + np.mean(green) + eps)\n",
    "    features.append(color_index)\n",
    "    \n",
    "    # 13. Redness Index (1 feature) - R^2 / (B * G^3)\n",
    "    redness_index = (np.mean(red) ** 2) / (np.mean(blue) * (np.mean(green) ** 3) + eps)\n",
    "    features.append(redness_index)\n",
    "    \n",
    "    # Toplam 29 özellik\n",
    "    return np.array(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verilerin okunması \n",
    "\n",
    "flaming ve pizza klasörlerinden tüm resimler alınır ve cv2 kütüphanesi ile okunur. (128,128) boyutuna resize edilir. Daha sonra resimlerin ve etiketlerin bir listesi oluşturulur. Etiketler flaming için 0, pizza için 1 olarak belirlenir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri yükleme iyileştirmeleri\n",
    "def load_data(base_path):\n",
    "    classes = ['flamingo', 'pizza']\n",
    "    all_images = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        path = os.path.join(base_path, class_name)\n",
    "        images = glob.glob(os.path.join(path, '*.jpg'))\n",
    "        \n",
    "        for img_path in images:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(\"Bozuk resim:\", img_path)\n",
    "                continue  # Bozuk resimleri atla\n",
    "            \n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            features = extract_features(img.flatten())\n",
    "            \n",
    "            all_images.append(features)\n",
    "            labels.append(class_idx)\n",
    "    \n",
    "    return np.array(all_images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train \n",
    "\n",
    "Perceptron işlemleri için trainPerceptron metodunun gerçeklenmesi \n",
    "Önce feed forward, ardından back forward işlemleri gerçekenir. Her adımda shuffle kullanılır. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPerceptron(inputs, t, weights, rho=0.01, iterNo=1000, batch_size=1):\n",
    "    \"\"\"\n",
    "    inputs:  (N x 30)  -> her örneğin özellik + bias vektörü\n",
    "    T:       (N x 2)   -> one-hot enc. (örn. flamingo=[1,0], pizza=[0,1])\n",
    "    W:       (30 x 2)  -> başlangıç ağırlık matrisi\n",
    "    rho:     öğrenme oranı\n",
    "    iterNo:  epoch sayısı\n",
    "    \"\"\"\n",
    "    X_bias = np.c_[inputs, np.ones(len(t))]\n",
    "    \n",
    "    for epoch in range(iterNo):\n",
    "        X_shuffled, y_shuffled = shuffle(X_bias, t)\n",
    "        \n",
    "        for i in range(0, len(X_shuffled), batch_size):\n",
    "            batch_X = X_shuffled[i:i+batch_size]\n",
    "            batch_y = y_shuffled[i:i+batch_size]\n",
    "            \n",
    "            # Forward pass\n",
    "            z = batch_X @ weights\n",
    "            a = Swish(z)\n",
    "            \n",
    "            # Backward pass\n",
    "            error = a - batch_y\n",
    "            delta = error * dSwish(z)\n",
    "            gradient = batch_X.T @ delta\n",
    "            \n",
    "            # Update with momentum\n",
    "            weights -= rho * gradient / batch_size\n",
    "        \n",
    "        # Her 100 epoch'ta değerlendirme\n",
    "        if epoch % 100 == 0:\n",
    "            preds = Swish(X_bias @ weights) > 0.5\n",
    "            acc = accuracy_score(t, preds)\n",
    "            print(f\"Epoch {epoch}: Accuracy {acc:.4f}\")\n",
    "            \n",
    "    np.save('weights.npy', weights) # save\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test \n",
    "\n",
    "Aynı şekilde Test kodu :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testPerceptron(X, y, weights):\n",
    "    X_bias = np.c_[X, np.ones(len(X))]\n",
    "    preds = Swish(X_bias @ weights) > 0.5\n",
    "    acc = accuracy_score(y, preds)\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main\n",
    "\n",
    "Resim verileri load_data metodu ile X, Y olarak ayrıştırılır ve StandartScaler ile transform edilir. Ardından train_test_split ile %80 train %20 test olarak ayrılır. Bias değerleri de eklendikten sonra ağırlıklar dimension boyutunda initialize edilir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = load_data(\"CaltechTiny2\")\n",
    "\n",
    "# Veri normalleştirme\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Veri ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Ağırlık başlatma (Xavier)\n",
    "input_dim = X_train.shape[1] + 1\n",
    "weights = np.random.randn(input_dim) * np.sqrt(2.0 / input_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x ve y train verileri trainPerceptron metoduna gönderilerek model eğitilir ve ardından kaydedilen ağırlıklar weights.npy içerisinden okunur. Prediction işlemi bu okunan ağırlıklar ile yapılır ve gerekli metrikler gösterilir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train seti üzerinde tahminler yapılıyor...\n",
      "Epoch 0: Accuracy 0.7083\n",
      "Epoch 100: Accuracy 0.8958\n",
      "Epoch 200: Accuracy 0.8958\n",
      "Epoch 300: Accuracy 0.9167\n",
      "Epoch 400: Accuracy 0.8958\n",
      "Epoch 500: Accuracy 0.9062\n",
      "Epoch 600: Accuracy 0.8958\n",
      "Epoch 700: Accuracy 0.9271\n",
      "Epoch 800: Accuracy 0.9167\n",
      "Epoch 900: Accuracy 0.8958\n",
      "Eğitim tamamlandı ve ağırlıklar kaydedildi.\n",
      "----------------------------------------------------------------\n",
      "Test seti üzerinde tahminler yapılıyor...\n",
      "Test Accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Train seti üzerinde tahminler yapılıyor...\")\n",
    "# Eğitim\n",
    "trainPerceptron(X_train, y_train, weights, rho=0.01, iterNo=1000)\n",
    "weights = np.load('weights.npy')  # load\n",
    "print(\"Eğitim tamamlandı ve ağırlıklar kaydedildi.\")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "\n",
    "# Test seti üzerinde tahmin yapma\n",
    "print(\"Test seti üzerinde tahminler yapılıyor...\")\n",
    "# predictions = Swish(np.c_[X_test, np.ones(len(X_test))] @ weights) > 0.5\n",
    "predictions = testPerceptron(X_test, y_test, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karmaşıklık Matrisi:\n",
      "[[11  2]\n",
      " [ 0 11]]\n",
      "Sınıflandırma Raporu:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Flamingo       1.00      0.85      0.92        13\n",
      "       Pizza       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.92        24\n",
      "   macro avg       0.92      0.92      0.92        24\n",
      "weighted avg       0.93      0.92      0.92        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# confusion matrisi\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(\"Karmaşıklık Matrisi:\")\n",
    "print(cm)\n",
    "\n",
    "# diğer metrikler \n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Sınıflandırma Raporu:\")\n",
    "print(classification_report(y_test, predictions, target_names=['Flamingo', 'Pizza']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
